{"cells":[{"cell_type":"markdown","source":["# **Homework 21: Natural Language Processing II**\n","---\n","\n","### **Description**\n","In this week's homework, you will see how to use more advanced forms of neural nets to perform tasks in NLP such as classification and generation.\n","\n","<br>\n","\n","### **Structure**\n","**Part 1**: Sarcasm Detection in the News\n","\n","\n","\n","\n","<br>\n","\n","### **Cheat Sheets**\n","[Natural Language Processing II](https://docs.google.com/document/d/1p3xVUL1F6SEkusCI4klPLYqQwCkVN5s00ZvJjBpiSqM/edit?usp=sharing)\n","\n","<br>\n","\n","**Before starting, run the code below to import all necessary functions and libraries.**"],"metadata":{"id":"dTIoQdGufbcb"}},{"cell_type":"code","source":["!pip install lime\n","\n","from lime import lime_text\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","import numpy as np\n","import os\n","\n","from keras.models import Sequential\n","from keras.layers import *\n","from keras.optimizers import Adam, SGD\n","from keras.utils import to_categorical\n","\n","from sklearn.model_selection import train_test_split\n","\n","from random import choices\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"yWd0JEE9fmrW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704489687812,"user_tz":480,"elapsed":19202,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"6956b67c-0400-4200-dff0-614a22955283"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.12.9)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.5.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283835 sha256=46481b7ae74bdc6fb2b192104840cf6526c282f5f31834180104fcd7a0fb2287\n","  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n","Successfully built lime\n","Installing collected packages: lime\n","Successfully installed lime-0.2.0.1\n"]}]},{"cell_type":"markdown","source":["---\n","## **Part 1: Sarcasm Detection in the News**\n","---\n","\n","In this section, we will see how to apply what we learned yesterday in combination with more advanced tools to determine how sarcastic a given text is.\n","\n","<br>\n","\n","We will be working with a dataset containing the headline of many news articles and a classification of whether that headline is sarcastic or not.\n","\n","<br>\n","\n","\n","**Run the code provided below to import the dataset.**"],"metadata":{"id":"iSkUvAmLfB78"}},{"cell_type":"code","source":["data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vTHrKLcHxF-DSkeH5FMmpFm5KQzDbzdaCdj1aP89wmUVIg_TxLPaveVXt1C8kG2b3aLnuON6cqfABd5/pub?output=csv')\n","data.head()\n","\n","x_train, x_test, y_train, y_test = train_test_split(data[\"headline\"], data[\"is_sarcastic\"], test_size = 0.2, random_state = 42)\n","\n","x_train = np.array(x_train)\n","x_test = np.array(x_test)\n","\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"metadata":{"id":"wLXOcKuBfod0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","### **Part 1.1:  Simple Deep Neural Networks**\n","---\n","\n","In this section, you will use dense layers provided by keras to build a simple DNN."],"metadata":{"id":"OgvzN47sq0oa"}},{"cell_type":"markdown","source":["#### **Problem #1.1.1: Create the `TextVectorization` layer**\n","\n","\n","To get started, let's create a `TextVectorization` layer to vectorize this data.\n","\n","Specifically,\n","1. Initialize the layer with the specified parameters.\n","\n","2. Adapt the layer to the training data.\n","\n","3. Look at the newly built vocabulary."],"metadata":{"id":"LTm3147qiKE4"}},{"cell_type":"markdown","source":["##### **1.Initialize the layer with the specified parameters.**\n","\n","* The vocabulary should be at most 2000 words.\n","* The layer's output should always be 20 integers."],"metadata":{"id":"d3zfKfgAiKE4"}},{"cell_type":"code","source":[],"metadata":{"id":"Lc6-HJGhiKE4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **2. Adapt the layer to the training data.**"],"metadata":{"id":"Bif_POk3iKE5"}},{"cell_type":"code","source":[],"metadata":{"id":"bsnDnHGFiKE5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **3. Look at the newly built vocabulary.**"],"metadata":{"id":"ovHm-Icy2iZv"}},{"cell_type":"code","source":[],"metadata":{"id":"bnAtuO3B2iZw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Problem #1.1.2: Build the model**\n","\n","\n","Complete the code below to build a model with the following layers.\n","\n","An `Embedding` layer such that:\n","* The vocabulary contains 2000 tokens.\n","* The input length corresponds to the output of the vectorization layer.\n","* The number of outputs per input is 128.\n","\n","<br>\n","\n","Hidden layers:\n","\n","* A  `Flatten` layer.\n","* A  `Dense` layer with 64 units (hidden states).\n","\n","<br>\n","\n","An output `Dense` layer. You can use activation `softmax`."],"metadata":{"id":"_ULrKEoKiKE6"}},{"cell_type":"code","source":["model = Sequential()\n","\n","# Input, Vectorization, and Embedding Layers\n","model.add(Input(shape=(1,), dtype=tf.string))\n","model.add(vectorize_layer)\n","model.add(Embedding(# COMPLETE THIS LINE\n","\n","# Hidden Layers\n","model.add(# COMPLETE THIS LINE\n","\n","# Output Layer\n","model.add(# COMPLETE THIS LINE"],"metadata":{"id":"qliSJAYCiKE6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1678876711038,"user_tz":-60,"elapsed":10,"user":{"displayName":"Eranda Bregasi","userId":"06402694060653755536"}},"outputId":"313f519a-84a2-4a9c-8a46-251b1a8defac"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-6c51cf3a7eaf>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    model.add(# COMPLETE THIS LINE\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}]},{"cell_type":"markdown","source":["#### **Problem #1.1.3: Compile and fit the model**\n","\n","\n","Using standard parameters for classification, compile and train this neural network using:\n","* A learning rate of 0.01.\n","* A batch size of 200.\n","* 5 epochs."],"metadata":{"id":"RMhg0mcliKE6"}},{"cell_type":"code","source":["opt = Adam(learning_rate = # COMPLETE THIS LINE\n","model.compile(optimizer = opt, loss = # COMPLETE THIS LINE\n","\n","model.fit(# COMPLETE THIS LINE"],"metadata":{"id":"GIWQr3UFiKE6","colab":{"base_uri":"https://localhost:8080/","height":135},"executionInfo":{"status":"error","timestamp":1679292204185,"user_tz":-60,"elapsed":382,"user":{"displayName":"Eranda Bregasi","userId":"06402694060653755536"}},"outputId":"47dbe164-3533-49bc-971f-c084b76787e3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e3a99cb8abb9>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    model.fit(# COMPLETE THIS LINE\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}]},{"cell_type":"markdown","source":["#### **Problem #1.1.4: Evaluate the model**\n","\n","\n","Now, evaluate the model for both the training and test sets."],"metadata":{"id":"rZDdIc2LiKE7"}},{"cell_type":"code","source":[],"metadata":{"id":"rtdeiWm7iKE7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","### **Part 1.2: Convolutional Neural Nets**\n","---\n","\n","In this section, you will approach the same problem using the `Conv1D` and `MaxPooling1D` layers provided by keras."],"metadata":{"id":"3D8iKE2U0eZx"}},{"cell_type":"markdown","source":["#### **Problem #1.2.1: Build a CNN**\n","\n","\n","Complete the code below to build, *but not train*, a new CNN model. Specifically, create a model identical to the ones above except with hidden layers as follows:\n","\n","* A `Conv1D` layer with `filters = 1`, `kernel_size = 4`, and `activation = 'relu'`.\n","* A `MaxPooling1D` layer with `pool_size = 2`."],"metadata":{"id":"sKbPF8Z9LAWX"}},{"cell_type":"code","source":["model = Sequential()\n","\n","# Input, Vectorization, and Embedding Layers\n","# COMPLETE THIS CODE\n","\n","\n","# Hidden Layers\n","# COMPLETE THIS CODE\n","\n","\n","# Output Layer\n","# COMPLETE THIS CODE"],"metadata":{"id":"S4_oXj-uLAWY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Problem #1.2.2: Examine the CNN's structure**\n","\n","\n","Now, let's look at the structure of this neural network.\n","\n","**Run the code below to print the input and output shapes of each layer.**"],"metadata":{"id":"QFEo-5xuVk2J"}},{"cell_type":"code","source":["for layer in model.layers:\n","  print(str(layer.input_shape) + \" -> \" + str(layer.output_shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MtSHQoz0Vv2t","executionInfo":{"status":"ok","timestamp":1678876740605,"user_tz":-60,"elapsed":3,"user":{"displayName":"Eranda Bregasi","userId":"06402694060653755536"}},"outputId":"11118923-1938-41cb-9aa0-c00c3b8ed25c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(None, 1) -> (None, 20)\n","(None, 20) -> (None, 20, 128)\n","(None, 20, 128) -> (None, 17, 1)\n","(None, 17, 1) -> (None, 8, 1)\n","(None, 8, 1) -> (None, 8)\n","(None, 8) -> (None, 2)\n"]}]},{"cell_type":"markdown","source":["#### **Problem #1.2.3: Train and Evaluate the CNN**\n","\n","\n","Now, complete the code below to train and evaluate this model."],"metadata":{"id":"ZjQMsF11VyHq"}},{"cell_type":"code","source":["# Fitting\n","opt = Adam(learning_rate = 0.001)\n","model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","model.fit(x_train, y_train, epochs = 5, batch_size = 256)\n","\n","\n","# Evaluating\n","print(\"\\n\\n\\n\")\n","model.evaluate(# COMPLETE THIS LINE\n","model.evaluate(# COMPLETE THIS LINE"],"metadata":{"id":"9H-BY04zV5BG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Problem #1.2.4: Adjust the model**\n","\n","\n","Complete the code below to train a new CNN model. Specifically, create a model identical to the ones above except with hidden layers as follows:\n","\n","* A `Conv1D` layer with `filters = 64`, `kernel_size = 3`, and `activation = 'relu'`.\n","* A `MaxPooling1D` layer with `pool_size = 2`."],"metadata":{"id":"aCfKk9hkPB2a"}},{"cell_type":"code","source":["model = Sequential()\n","\n","# Input, Vectorization, and Embedding Layers\n","# COMPLETE THIS CODE\n","\n","\n","# Hidden Layers\n","# COMPLETE THIS CODE\n","\n","\n","# Output Layer\n","# COMPLETE THIS CODE\n","\n","\n","# Printing Structure\n","for layer in model.layers:\n","  print(str(layer.input_shape) + \" -> \" + str(layer.output_shape))\n","print(\"\\n\\n\\n\")\n","\n","\n","# Fitting\n","# COMPLETE THIS CODE\n","\n","\n","# Evaluating\n","print(\"\\n\\n\\n\")\n","# COMPLETE THIS CODE"],"metadata":{"id":"G9LN8miLPB2k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Problem #1.2.5: Improve the model**\n","---\n","\n","You are likely seeing that this last model performs better on the test set than most others you have seen today. It will be challenging to beat this; however, see if you can improve the model any more by adjusting any parameters including:\n","\n","* **Number of filters**: Can we get away with fewer filters? Should we add more filters?\n","* **Kernel size**: What happens when we change this more significantly?\n","* **Pool size**: Should we be pooling more inputs together or fewer?\n","* **Dense layers**: Would adding any dense layers after the convolved results are pooled and flatten help?\n","* **Number of convolutional and pooling layers**: If you're careful about the input and output shapes, it is possible to stack multiple convolutional and pooling layers.\n","* **Training parameters**: Would it help to adjust the learning rate, number of epochs, or batch size?"],"metadata":{"id":"2unPUULPWy_T"}},{"cell_type":"code","source":["model = Sequential()\n","\n","# Input, Vectorization, and Embedding Layers\n","# COMPLETE THIS CODE\n","\n","\n","# Hidden Layers\n","# COMPLETE THIS CODE\n","\n","\n","# Output Layer\n","# COMPLETE THIS CODE\n","\n","\n","# Fitting\n","# COMPLETE THIS CODE\n","\n","\n","# Evaluating\n","print(\"\\n\\n\\n\")\n","# COMPLETE THIS CODE"],"metadata":{"id":"UAbzdj1dWy_c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7dzC09dLlEhm"},"source":["---\n","#End of notebook\n","\n","© 2024 The Coding School, All rights reserved"]}],"metadata":{"colab":{"provenance":[{"file_id":"1VbvC84SrV5ZOKxogfQXvwey0-q3TipJY","timestamp":1678175654957}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}