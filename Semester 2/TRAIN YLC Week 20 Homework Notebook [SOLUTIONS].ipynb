{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PupwQQp6LZFfMIPgWLKlWXrYDgLuA5sj","timestamp":1678127175525}],"collapsed_sections":["7dzC09dLlEhm"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Homework 20: Natural Language Processing I**\n","---\n","\n","### **Description**\n","In this week's homework, you will apply what you learned in this week's lab to classify emails as either `\"spam\"` or `\"not spam\"`.\n","\n","\n","<br>\n","\n","### **Structure**\n","**Part 1**: Detecting Spam Emails with a DNN\n","\n","**Part 2**: Detecting Spam Emails with a CNN\n","\n","\n","\n","\n","<br>\n","\n","### **Cheat Sheets**\n","[Natural Language Processing I](https://docs.google.com/document/d/1ZaLtMF7aQsG05myetJpoTJlr-sAIURP_a9sQr66pfqw/edit?usp=drive_link)\n","\n","<br>\n","\n","**Before starting, run the code below to import all necessary functions and libraries.**"],"metadata":{"id":"N61ZizxuBc3E"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import *\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","\n","from sklearn.model_selection import train_test_split\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"YAvvLhRIoqYp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","## **Part 1: Detecting Spam Emails with a DNN**\n","---\n","\n","\n","**Run the code provided below to import the dataset.**"],"metadata":{"id":"idga37M2FsMR"}},{"cell_type":"code","source":["df = pd.read_excel('https://docs.google.com/spreadsheets/d/e/2PACX-1vQaAZH50du-EP6meYf_LjHztynjYFZ2mg1miSvjgz8nLNh_lnbSdgARSQC10UdhhQ/pub?output=xlsx')\n","\n","inputs = df[[\"Column2\"]]\n","output = df[\"Column1\"]\n","\n","x_train, x_test, y_train, y_test = train_test_split(inputs, output, test_size=0.2, random_state=42)"],"metadata":{"id":"In9BSfqd_OPA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Exercise #1.1: Create the `TextVectorization` layer**\n","\n","\n","Let's create a `TextVectorization` layer to vectorize this data.\n","\n","Specifically,\n","1. Initialize the layer with the specified parameters.\n","\n","2. Adapt the layer to the training data."],"metadata":{"id":"E90o2LJcwsMI"}},{"cell_type":"markdown","source":["##### **1. Initialize the layer with the specified parameters.**\n","\n","* `max_tokens = 5000`\n","* `output_mode = 'int'`\n","* `output_sequence_length = 50`"],"metadata":{"id":"koGBxiapJC_y"}},{"cell_type":"code","source":["vectorize_layer = TextVectorization(\n","    # WRITE YOUR CODE HERE\n","  )\n","\n","vectorize_layer.adapt(x_train)"],"metadata":{"id":"SVG1Sy7OJU0s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"Z5jzUynnJU0t"}},{"cell_type":"code","source":["vectorize_layer = TextVectorization(\n","    max_tokens = 5000,\n","    output_mode = 'int',\n","    output_sequence_length = 50\n","  )\n","\n","vectorize_layer.adapt(x_train)"],"metadata":{"id":"xLcL6cn5JU0t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Exercise #1.2: Look at the vocabulary**\n","\n","\n","Print the first 50 words of the vocabulary."],"metadata":{"id":"Vz2dKD8pJhXa"}},{"cell_type":"code","source":["# WRITE YOUR CODE HERE"],"metadata":{"id":"3pDiV7anAv60"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**"],"metadata":{"id":"gPP6D-qZAwUd"}},{"cell_type":"code","source":["vectorize_layer.get_vocabulary()[0:50]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pA6CEFVtDeQa","executionInfo":{"status":"ok","timestamp":1704421232076,"user_tz":480,"elapsed":188,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"064a2ad1-292a-4e70-dce6-be8613a2f6a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '[UNK]',\n"," 'the',\n"," 'and',\n"," 'for',\n"," 'you',\n"," 'this',\n"," 'that',\n"," 'enron',\n"," 'will',\n"," 'with',\n"," 'ect',\n"," 'have',\n"," 'from',\n"," 'are',\n"," 'your',\n"," 'hou',\n"," 'our',\n"," 'not',\n"," 'would',\n"," 'has',\n"," 'all',\n"," 'ees',\n"," 'please',\n"," 'can',\n"," 'any',\n"," 'com',\n"," 'they',\n"," 'but',\n"," 'out',\n"," 'get',\n"," 'was',\n"," 'more',\n"," 'power',\n"," 'been',\n"," 'which',\n"," 'also',\n"," 'energy',\n"," 'some',\n"," 'kitchen',\n"," 'one',\n"," 'these',\n"," 'time',\n"," 'there',\n"," 'over',\n"," 'need',\n"," 'subject',\n"," 'what',\n"," 'know',\n"," 'their']"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["#### **Exercise #1.3: Add the input and text vectorization layers to the model**\n","\n","\n"],"metadata":{"id":"zTCj-Z7rJ5on"}},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Input(# COMPLETE THIS LINE\n","model.add(# COMPLETE THIS LINE"],"metadata":{"id":"RYh5A78OKRhm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"qnyPW50LKRE0"}},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Input(shape=(1,), dtype=tf.string))\n","model.add(vectorize_layer)"],"metadata":{"id":"0qIl7LcrD8B3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Exercise #1.4: Look at the vectorization of an example**\n","\n","\n","Add your own sentence below to see how it would be vectorized with our newly adapted layer.\n","\n","<br>\n","\n","**NOTE:** `TextVectorizer` will ignore any punctuation and consider upper and lower case the same. There are extra parameters that can set to adjust this."],"metadata":{"id":"Ohs_ludzKcE9"}},{"cell_type":"code","source":["vector_0 = model.predict([# COMPLETE THIS LINE\n","\n","print(vector_0)\n","print(vector_0.shape)"],"metadata":{"id":"PZoit5S6OnPj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"FGHYd5ODOmkh"}},{"cell_type":"code","source":["vector_0 = model.predict(['hello world my name is Adam'])\n","\n","print(vector_0)\n","print(vector_0.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_RHvezKFPhN","executionInfo":{"status":"ok","timestamp":1704397224645,"user_tz":480,"elapsed":1670,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"b8a19dbe-90df-4bd7-ac1f-70114e2e00db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","[[1176  379    1  229    1    1    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0]]\n","(1, 50)\n"]}]},{"cell_type":"markdown","source":["#### ***STOP!* Answer the following question under Problem #8: When using the text vectorization layer in Keras, what do the numbers in the vectorization represent?**"],"metadata":{"id":"fSpGeUg0RoBA"}},{"cell_type":"markdown","source":["#### **Exercise #1.5: Add hidden layers and an output layer**\n","\n","\n","Add two dense layers with 512 neurons and ReLU activation.\n","\n","Then, because this is a binary classification task, create the output layer with a single neuron (for spam/not spam) and the sigmoid activation function."],"metadata":{"id":"eN8Z-C_3K0ZG"}},{"cell_type":"code","source":["model.add(Dense(# COMPLETE THIS LINE\n","model.add(Dense(# COMPLETE THIS LINE\n","model.add(Dense(# COMPLETE THIS LINE"],"metadata":{"id":"liLaJe3dLPN9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"4gQATg_-LROR"}},{"cell_type":"code","source":["model.add(Dense(1000, activation = 'relu'))\n","model.add(Dense(1000, activation = 'relu'))\n","model.add(Dense(1, activation = 'sigmoid'))"],"metadata":{"id":"eBLxBovbFO8A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's take a look at our DNN."],"metadata":{"id":"zYru7HAFGz3B"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VI8Yhy61G2Ar","executionInfo":{"status":"ok","timestamp":1704397229954,"user_tz":480,"elapsed":150,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"c3109644-279a-40d2-f004-4193489c8789"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," text_vectorization_1 (Text  (None, 50)                0         \n"," Vectorization)                                                  \n","                                                                 \n"," dense (Dense)               (None, 1000)              51000     \n","                                                                 \n"," dense_1 (Dense)             (None, 1000)              1001000   \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 1001      \n","                                                                 \n","=================================================================\n","Total params: 1053001 (4.02 MB)\n","Trainable params: 1053001 (4.02 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["#### **Exercise #1.6: Compile and fit the model**\n","\n","\n","Compile and fit the model with the following parameters:\n","* Adam learning rate of 0.001\n","* `binary_crossentropy` for the loss function\n","* Accuracy as the metric\n","* For the fit, use `epochs=5` and `batch_size=128`"],"metadata":{"id":"fuGPjq1bLSNA"}},{"cell_type":"code","source":["opt = Adam(learning_rate = # COMPLETE THIS LINE\n","model.compile(optimizer = opt, loss = # COMPLETE THIS LINE\n","\n","model.fit(# COMPLETE THIS LINE"],"metadata":{"id":"rjiBv6JzLk4C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"xL3OlsDjLzsE"}},{"cell_type":"code","source":["opt = Adam(learning_rate = 0.001)\n","model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","model.fit(x_train, y_train, epochs = 5, batch_size = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3FnosgSESX4","executionInfo":{"status":"ok","timestamp":1704397236005,"user_tz":480,"elapsed":3721,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"9e8660ad-fb15-423d-d726-ab77fc8606c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","7/7 [==============================] - 2s 10ms/step - loss: 365.8608 - accuracy: 0.5275\n","Epoch 2/5\n","7/7 [==============================] - 0s 7ms/step - loss: 164.8934 - accuracy: 0.5400\n","Epoch 3/5\n","7/7 [==============================] - 0s 7ms/step - loss: 63.3811 - accuracy: 0.5950\n","Epoch 4/5\n","7/7 [==============================] - 0s 6ms/step - loss: 32.2267 - accuracy: 0.6687\n","Epoch 5/5\n","7/7 [==============================] - 0s 6ms/step - loss: 17.5359 - accuracy: 0.6888\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ec1b399f910>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["#### ***STOP!* Answer the following question under Problem #9: Why are we using the binary crossentropy loss function instead of the categorical crossentropy function for this task?**"],"metadata":{"id":"CFEwGmJRTOyO"}},{"cell_type":"markdown","source":["#### **Exercise #1.7: Evaluate the model**\n","\n","\n","Now, evaluate the model for both the training and test sets.\n","\n","<br>\n","\n","**NOTE:** As a baseline, randomly guessing 1 out of 4 possible classes would achieve a roughly 0.25 accuracy."],"metadata":{"id":"JSOOynZqL0xo"}},{"cell_type":"code","source":["# Evaluate the training set\n","model.evaluate(# COMPLETE THIS LINE\n","\n","# Evaluate the test set\n","model.evaluate(# COMPLETE THIS LINE"],"metadata":{"id":"HqPSJlsSL7_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"KhhEcdN2L7Nc"}},{"cell_type":"code","source":["model.evaluate(x_train, y_train)\n","model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GchfUp2aIc83","executionInfo":{"status":"ok","timestamp":1704397239451,"user_tz":480,"elapsed":752,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"5a247009-2a46-4cc4-9e2a-48e9e09ae6e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25/25 [==============================] - 0s 3ms/step - loss: 6.3736 - accuracy: 0.7912\n","7/7 [==============================] - 0s 10ms/step - loss: 23.0898 - accuracy: 0.5700\n"]},{"output_type":"execute_result","data":{"text/plain":["[23.089759826660156, 0.5699999928474426]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["---\n","## **Part 2: Detecting Spam Emails with a CNN**\n","---\n"],"metadata":{"id":"r4_U4kWylKLw"}},{"cell_type":"markdown","source":["#### **Exercise #2.1: Initialize the model with an input and vectorizer layer**\n","\n","\n","*Hint: This is the same as last time.*"],"metadata":{"id":"VN8Z0gy_sExR"}},{"cell_type":"code","source":["cnn_model = # COMPLETE THIS LINE\n","\n","cnn_model.add(Input(# COMPLETE THIS LINE\n","cnn_model.add(# COMPLETE THIS LINE"],"metadata":{"id":"LvS3JpkcsZI2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"exLTTU5JtntN"}},{"cell_type":"code","source":["cnn_model = Sequential()\n","\n","cnn_model.add(Input(shape=(1,), dtype=tf.string))\n","cnn_model.add(vectorize_layer)"],"metadata":{"id":"z6DOyy7etntN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Exercise #2.2: Finish building the CNN**\n","\n","\n","Build your CNN with the following layers:\n","* a convolutional layer with 128 filters, a kernel size of 5, and ReLU activation\n","* a max pooling layer with a pool size of 2\n","* a convolutional layer with 256 filters, a kernel size of 5, and ReLU activation\n","* a max pooling layer with a pool size of 2\n","* a flatten layer\n","* a dense layer with 512 neurons\n","* the output layer"],"metadata":{"id":"9kV4xruit_UF"}},{"cell_type":"code","source":["# The convolution layer requires us to cast the inputs to a different data type\n","# and reshape the input as well. We have done this for you.\n","cnn_model.add(Lambda(lambda x: tf.cast(x, 'float32')))\n","cnn_model.add(Reshape((50, 1)))\n","\n","# Start building your CNN below.\n","# WRITE YOUR CODE HERE"],"metadata":{"id":"8SQd40rbnOrq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**"],"metadata":{"id":"b6IWnBGBnPbi"}},{"cell_type":"code","source":["# The convolution layer requires us to cast the inputs to a different data type\n","# and reshape the input as well. We have done this for you.\n","cnn_model.add(Lambda(lambda x: tf.cast(x, 'float32')))\n","cnn_model.add(Reshape((50, 1)))\n","\n","# Start building your CNN below.\n","cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n","cnn_model.add(MaxPooling1D(pool_size=2))\n","cnn_model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n","cnn_model.add(MaxPooling1D(pool_size=2))\n","cnn_model.add(Flatten())\n","cnn_model.add(Dense(512, activation = 'relu'))\n","cnn_model.add(Dense(1, activation = 'sigmoid'))"],"metadata":{"id":"QYEmDsS1ucWW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ***STOP!* Answer the following question under Problem #10: Why did we use the Conv1D layer instead of the Conv2D layer?**"],"metadata":{"id":"Friy0yo6TLiO"}},{"cell_type":"markdown","source":["Let's take a look at the completed model."],"metadata":{"id":"VfFAaOAOizPy"}},{"cell_type":"code","source":["cnn_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqK1H52pi1iZ","executionInfo":{"status":"ok","timestamp":1704397283634,"user_tz":480,"elapsed":154,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"90f0387a-f077-416c-d14b-569fa69eca78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," text_vectorization_1 (Text  (None, 50)                0         \n"," Vectorization)                                                  \n","                                                                 \n"," lambda (Lambda)             (None, 50)                0         \n","                                                                 \n"," reshape (Reshape)           (None, 50, 1)             0         \n","                                                                 \n"," conv1d (Conv1D)             (None, 46, 128)           768       \n","                                                                 \n"," max_pooling1d (MaxPooling1  (None, 23, 128)           0         \n"," D)                                                              \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 19, 256)           164096    \n","                                                                 \n"," max_pooling1d_1 (MaxPoolin  (None, 9, 256)            0         \n"," g1D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 2304)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 512)               1180160   \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 1345537 (5.13 MB)\n","Trainable params: 1345537 (5.13 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["#### **Exercise #2.3: Compile and fit the model**\n","\n","\n","Compile and fit the model with the same parameters as Part 1."],"metadata":{"id":"kRhmTL_2lOM9"}},{"cell_type":"code","source":["opt = Adam(# COMPLETE THIS LINE)\n","cnn_model.compile(# COMPLETE THIS LINE\n","\n","cnn_model.fit(# COMPLETE THIS LINE"],"metadata":{"id":"RKS-Rxcsla4f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**\n"],"metadata":{"id":"ZTyBqTsIlaW_"}},{"cell_type":"code","source":["opt = Adam(learning_rate = 0.001)\n","cnn_model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","cnn_model.fit(x_train, y_train, epochs = 5, batch_size = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGe4e4t4i9-9","executionInfo":{"status":"ok","timestamp":1704397303100,"user_tz":480,"elapsed":6412,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"bdc76655-f99f-40c5-e454-ad146ccad877"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","7/7 [==============================] - 4s 48ms/step - loss: 253.1467 - accuracy: 0.4938\n","Epoch 2/5\n","7/7 [==============================] - 0s 10ms/step - loss: 7.1837 - accuracy: 0.5050\n","Epoch 3/5\n","7/7 [==============================] - 0s 9ms/step - loss: 0.9476 - accuracy: 0.5888\n","Epoch 4/5\n","7/7 [==============================] - 0s 9ms/step - loss: 0.6917 - accuracy: 0.6075\n","Epoch 5/5\n","7/7 [==============================] - 0s 9ms/step - loss: 0.6381 - accuracy: 0.6263\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ec1a82e75b0>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["#### **Exercise #2.4: Evaluate the model**\n","\n","\n","Now, evaluate the model for both the training and test sets."],"metadata":{"id":"FTIEF_GHlGZA"}},{"cell_type":"code","source":["cnn_model.evaluate(# COMPLETE THIS LINE\n","cnn_model.evaluate(# COMPLETE THIS LINE"],"metadata":{"id":"1VJ42ZnfloOQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###### **Solution**"],"metadata":{"id":"99PwvRwPllgT"}},{"cell_type":"code","source":["cnn_model.evaluate(x_train, y_train)\n","cnn_model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qji3x9bcj2SF","executionInfo":{"status":"ok","timestamp":1704397306678,"user_tz":480,"elapsed":825,"user":{"displayName":"Angelique Membrido","userId":"04984385250682432912"}},"outputId":"c4a91bf7-9b68-4e04-f139-40b0aceaab30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25/25 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.6413\n","7/7 [==============================] - 0s 21ms/step - loss: 0.7203 - accuracy: 0.5950\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7203307151794434, 0.5950000286102295]"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["---\n","#End of notebook\n","\n","© 2024 The Coding School, All rights reserved"],"metadata":{"id":"7dzC09dLlEhm"}}]}