{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nERhJ0C6rpDV"
   },
   "source": [
    "# **Lab 8: K-Nearest Neighbors**\n",
    "---\n",
    "\n",
    "### **Description**\n",
    "In this lab, you will implement KNN (K-Nearest Neighbors) models. KNNs are a popular machine learning algorithm used for classification and regression tasks. Through this lab, you'll gain hands-on experience in building and training KNN models and using them to make accurate predictions. You'll get to see firsthand how KNN models work and how they can be used to solve real-world problems.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Structure**\n",
    "**Part 1**: [Breast Cancer Dataset](#p1)\n",
    "\n",
    "**Part 2**: [Spotify Dataset](#p2)\n",
    "\n",
    "**Part 3**: [Australia Dataset](#p3)\n",
    "\n",
    "**Part 4**: [[OPTIONAL] Homework Practice](#p4)\n",
    ">\n",
    "> **Part 4.1**: [Zoo Animal Classification Dataset](#p4.1)\n",
    ">\n",
    "> **Part 4.2**: [Classifying Stars](#p4.2)\n",
    ">\n",
    "> **Part 4.3**: [RGB Color Classification](#p4.3)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Learning Objectives**\n",
    "By the end of this lab, we will:\n",
    "* Recognize how to implement KNN models with sklearn.\n",
    "* Recognize how to evaluate KNN models with sklearn.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Resources**\n",
    "* [K-Nearest Neighbors with sklearn](https://docs.google.com/document/d/1rKyjjnRe5dq3StxXS03n6iXfJvTN7dJNJjWVGdCu6cM/edit?usp=sharing)\n",
    "\n",
    "* [pandas Commands](https://docs.google.com/document/d/1pLCyzig38Mop0Iib021X47S25WBEqZCWf7LRdpC8hGw/edit?usp=drive_link)\n",
    "\n",
    "* [Data Visualizations with matplotlib](https://docs.google.com/document/d/1tCKyB_E2A-S_rwTIN6JHE9lCQiK4DLTQTt25Lc-uQcs/edit?usp=drive_link)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Before starting, run the code below to import all necessary functions and libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J697Qi0eizBL"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, model_selection, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJyKQAWMv8sR"
   },
   "source": [
    "<a name=\"p1\"></a>\n",
    "\n",
    "---\n",
    "## **Part 1: Breast Cancer Dataset**\n",
    "---\n",
    "\n",
    "#### **About the Dataset**\n",
    "Breast cancer is one of the most common types of cancer in women. Each year in the United States, about 264,000 women are diagnosed with breast cancer. The abilty to detect it early is extremely important. The following dataset is taken from the [UCI ML Breast Cancer Wisconsin (Diagnostic) dataset](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)). The dataset contains mammography exam results and whether or not cancer was detected.\n",
    "\n",
    "The features are as follows:\n",
    "* `radius`\n",
    "* `texture`: standard deviation of gray-scale values\n",
    "* `perimeter`\n",
    "* `area`\n",
    "* `smoothness`: local variations in radius lengths\n",
    "* `compactness`: perimeter^2 / area - 1\n",
    "* `concavity`: severity of concave portions of the contour\n",
    "* `concave points`: number of concave portions of the contour\n",
    "* `symmetry`\n",
    "* `fractal dimension`: \"coastline approximation\" - 1\n",
    "\n",
    "Note: There is data recorded for the mean, standard error, and worst (or largest) for each feature, resulting in 30 total features.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Your Task**\n",
    "Using the Breast Cancer dataset, we will do the following:\n",
    "* Create a KNN classifier model that can be used to predict whether or not a patient has breast cancer.\n",
    "* Use the model to predict whether or not patient have breast cancer based on various mean radii and mean textures.\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl7GlNcov8sk"
   },
   "source": [
    "#### **Step #1: Load the data**\n",
    "\n",
    "Load in the `Breast Cancer Dataset`. You may refer to this [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3BGz5Bn-pV_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5twdSdPwv8sm"
   },
   "source": [
    "#### **Step #2: Decide independent and dependent variables**\n",
    "\n",
    "Complete the cell below to select our features and label. In particular, we will fit our classifier using the `\"mean radius\"` and `\"mean texture\"` features in order to predict whether the patient has breast cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTcXl8htv8sn"
   },
   "outputs": [],
   "source": [
    "features = df[# COMPLETE THIS CODE\n",
    "label = df[# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7v4MpODv8so"
   },
   "source": [
    "#### **Before we continue our steps, let's visualize our data.**\n",
    "\n",
    "Create a scatterplot that visualizes the correlation between your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFKhqHVZ_MIT"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7xKAJAJv8so"
   },
   "source": [
    "#### **Step #3: Split data into training and testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z77noZidv8so"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2prquWav8so"
   },
   "source": [
    "#### **Step #4: Import the KNN algorithm**\n",
    "\n",
    "**Run the code below to complete this step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kr38Jg-hv8so"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0jRPRihv8sp"
   },
   "source": [
    "#### **Step #5: Initialize the model and set hyperparameters**\n",
    "\n",
    "\n",
    "Let's set the *hyperparameter* `n_neighbors = 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pj-SSljv8sp"
   },
   "outputs": [],
   "source": [
    "model = # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNX80Tywv8sp"
   },
   "source": [
    "#### **Step #6: Fit your model and make predictions on the test set. Create a visualization if applicable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsVEczjev8sp"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIei-70av8sp"
   },
   "source": [
    "#### **Create a visualization**\n",
    "\n",
    "**Run the code below to visualize the decision boundary of this KNN model.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6PtowtXv8sp"
   },
   "outputs": [],
   "source": [
    "# Make the same scatter plot of the training data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(6, 30, 0.1),\n",
    "                     np.arange(6, 42, 0.1))\n",
    "z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z = z.reshape(xx.shape)\n",
    "\n",
    "ax.pcolormesh(xx, yy, z, alpha=0.1)\n",
    "\n",
    "for label, data in df.groupby('TARGET'):\n",
    "  ax.scatter(data[\"mean radius\"], data[\"mean texture\"], label=[\"Cancerous\",\"Healthy\"][label])\n",
    "\n",
    "ax.set_title(\"Decision Boundary of the KNN Classifier\")\n",
    "ax.set_xlabel(\"mean radius\")\n",
    "ax.set_ylabel(\"mean texture\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE3mnT_Pv8ss"
   },
   "source": [
    "#### **Wait for your instructor to continue.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-dQxm5Fv8ss"
   },
   "source": [
    "#### **Step #7: Evaluate your model**\n",
    "\n",
    "Print the accuracy and confusion matrix for your model's performance on the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE**: Here you can use `[\"Cancerous\",\"Healthy\"]` for the `display_labels` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNAYTrzUv8su"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score: \" # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxquOZx5v8su"
   },
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDdTaGE_v8su"
   },
   "source": [
    "#### **Step #8: Use the model**\n",
    "\n",
    "Predict whether the following patients have cancer or not:\n",
    "\n",
    "1. Is a patient with mean radius `15.5` and mean texture `31.2` likely to have cancer?\n",
    "2. Is a patient with mean radius `12.2` and mean texture `34.5` likely to have cancer?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1688575350265,
     "user": {
      "displayName": "Marie Angelique Membrido",
      "userId": "04984385250682432912"
     },
     "user_tz": 420
    },
    "id": "NaDHn0zav8su",
    "outputId": "3f96e762-7dbb-4236-c66b-0abb67131a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture\n",
      "0         15.5          31.2\n"
     ]
    }
   ],
   "source": [
    "patient1 = pd.DataFrame([[15.5, 31.2]], columns=[\"mean radius\", \"mean texture\"])\n",
    "\n",
    "prediction1 = model.# COMPLETE THIS CODE\n",
    "\n",
    "print(\"Patient 1 \" + str(['is likely', 'is not likely'][prediction1]) + \" to have cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTrrPGw0v8su"
   },
   "outputs": [],
   "source": [
    "patient2 = pd.DataFrame(# COMPLETE THIS CODE\n",
    "\n",
    "prediction2 = model.# COMPLETE THIS CODE\n",
    "\n",
    "print(\"Patient 2 \" + str(['is likely', 'is not likely'][prediction2]) + \" to have cancer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVPL2dHCW_Dj"
   },
   "source": [
    "### **Reflection question**\n",
    "Answer the following question: In the case of predicting breast cancer, do you think it's more important to reduce false positives or false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVQU5DEggnZK"
   },
   "source": [
    "### **Hyperparameter Tuning [OPTIONAL]**\n",
    "\n",
    "Run the given code below to find the optimal k for our model. What is this k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLEGaoyggnZK"
   },
   "outputs": [],
   "source": [
    "# Now lets see how accurate it is looking at all 30 variables\n",
    "\n",
    "# Load all columns of the dataset\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df.drop(columns='TARGET'), df[['TARGET']],\n",
    "                                      test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "scores = {}\n",
    "for n in range(1,50,2):\n",
    "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
    "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
    "    pred = full_model.predict(X_test)\n",
    "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
    "    scores[n] = score\n",
    "\n",
    "\n",
    "plt.title(\"Accuracy on Test set across Hyperparameter values\")\n",
    "print(scores)\n",
    "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
    "\n",
    "# ADDING THE PERFORMANCE FOR K = SQRT SIZE FOR REFERENCE\n",
    "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
    "full_model = KNeighborsClassifier(n_neighbors = k)\n",
    "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
    "pred = full_model.predict(X_test)\n",
    "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
    "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
    "\n",
    "\n",
    "top_score = max(scores.values())\n",
    "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
    "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# PRINTING THE RESULTS\n",
    "print(\"Top score of optimal classifier: \" + str(top_score))\n",
    "print(\"Best Value of K to use \" + str(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYR-x1kwlVJL"
   },
   "source": [
    "<a name=\"p2\"></a>\n",
    "\n",
    "---\n",
    "## **Part 2: Spotify Dataset**\n",
    "---\n",
    "#### **About the Dataset**\n",
    "Spotify is one of the most popular digital music streaming services with over 515 million monthly users. The following dataset from Spotify data looks at different qualities of songs like energy, key, loudness, and tempo to see if a song is a top or bottom hit.\n",
    "\n",
    "The features are as follows:\n",
    "* `artist`: song artist(s)\n",
    "* `song`: song title\n",
    "* `duration_ms`: the track length in milliseconds (ms)\n",
    "* `year`: the year the song was released\n",
    "* `top half`: whether or not the song is in the top half of hits\n",
    "* `danceability`: how suitable a track is for dancing (0.0: least danceable, 1.0: most danceable)\n",
    "* `energy`: perceptual measure of intensity and activity (0.0 - 1.0)\n",
    "* `key`: the key the track is in; integers map to pitches using standard Pitch Class notation (0: C, 1: C♯/D♭, 2:D, ..., 11: B)\n",
    "* `loudness`: the overall loudness of a track in decibels (dB)\n",
    "* `mode`: the modality of a track, or the type of scale from which its melodic content is derived (0: minor, 1: major)\n",
    "* `speechiness`: a measure of the presence of spoken words in the track (0-0.33: music and other non-speech-like tracks, 0.33-0.66: contain both music and speech, 0.66-1.0: most likely made entirely of spoken words (e.g. talk show, audio book, poetry))\n",
    "* `acousticness`: a confidence measure of whether or not the track is acoustic (0.0: low confidence, 1.0: high confidence)\n",
    "* `instrumentalness`: predicts whether or not a track contains vocals (0.0: vocal content, 1.0: no vocal content)\n",
    "* `liveness`: detects the presence of an audience in the recording ( > 0.8: strong likelihood the track was performed live)\n",
    "* `valence`: musical positiveness conveyed by the track (lower valence: more negative, higher valence: more positive)\n",
    "* `tempo`: the overall estimated tempo in beats per minute (BPM)\n",
    "* `genre`: the genre in which the track belongs\n",
    "* `explicit`: whether or not the song is explicit\n",
    "* `explicity binary`: whether or not the song is explicit (0: no, 1: yes)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Your Task**\n",
    "Using the Spotify dataset, you will do the following:\n",
    "* Create a KNN model that can predict whether a song will be a hit or a bust;\n",
    "* Predict whether songs with various keys and energies will be hits or busts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPZneE0f5EPC"
   },
   "source": [
    "#### **Step #1: Load the data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO6Vymh7_bsH"
   },
   "outputs": [],
   "source": [
    "url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQJ9UIsI2j8vPnefdBj6GIrUGiDMsF5HRVAg4rsfaZqX5fAoTGLGydLvPXPQvE5ZSo9_aet1SC5UQji/pub?gid=1132556054&single=true&output=csv\"\n",
    "\n",
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7FdHFQh5Hu8"
   },
   "source": [
    "#### **Step #2: Decide independent and dependent variables**\n",
    "\n",
    "For this problem, we are interested in how the `key` and `energy` affect whether or not a song becomes a hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRxe-es59l3t"
   },
   "outputs": [],
   "source": [
    "features = spotify_df[# COMPLETE THIS CODE\n",
    "label = spotify_df[# COMPLETE THIS CODE\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(# COMPLETE THIS CODE\n",
    "\n",
    "# yellow: top hit, purple: bottom hit\n",
    "plt.title(\"Energy vs. Key of Hit Songs Colored by Whether they were a Top or Bottom Hit\")\n",
    "plt.xlabel(\"Key\")\n",
    "plt.ylabel(\"Energy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8utEQrU558Xw"
   },
   "source": [
    "#### **Step #3: Split data into training and testing data**\n",
    "\n",
    "Split the data as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Kdf8XXMdIrr"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvENbkqU562F"
   },
   "source": [
    "#### **Step #4: Import the KNN algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3JRpVw3dUpH"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk8ZPWRJ6Hrq"
   },
   "source": [
    "#### **Step #5: Initialize the model and set hyperparameters**\n",
    "\n",
    "Let's set the *hyperparameter* `n_neighbors = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRDPWV3EdVhe"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3He9SfO86NvK"
   },
   "source": [
    "#### **Step #6: Fit your model and make a prediction. Create a visualization if applicable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJZ4gQ0rgoJs"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWSoWSi5-gX4"
   },
   "source": [
    "#### **Create a visualization**\n",
    "\n",
    "**Run the code below to visualize the decision boundary of this KNN model.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMRHsvj4-gX5"
   },
   "outputs": [],
   "source": [
    "# Make the same scatter plot of the training data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(spotify_df['key'].min() - 1, spotify_df['key'].max() + 1, 0.1),\n",
    "                     np.arange(spotify_df['energy'].min() - 0.1, spotify_df['energy'].max() + 0.1, 0.1))\n",
    "z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z = z.reshape(xx.shape)\n",
    "\n",
    "ax.pcolormesh(xx, yy, z, alpha=0.1)\n",
    "\n",
    "for label, data in spotify_df.groupby('top half'):\n",
    "  ax.scatter(data[\"key\"], data[\"energy\"], label=['lower half', 'top half'][label])\n",
    "\n",
    "ax.set_title(\"Decision Boundary of the KNN Classifier\")\n",
    "ax.set_xlabel(\"Key\")\n",
    "ax.set_ylabel(\"Energy\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlMCxDa_-W1f"
   },
   "source": [
    "#### **Step #7: Evaluate your model**\n",
    "\n",
    "Print the accuracy and confusion matrix for your model's performance on the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE**: You can use `['top half', 'bottom half']` for the `display_labels` argument here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbsBftHbFpUT"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score: \" + # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8W9uuTe-W1g"
   },
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj2QnHkE7J9E"
   },
   "source": [
    "#### **Step #8: Use the model**\n",
    "\n",
    "Use your model to predict whether the following songs are in the top hits.\n",
    "\n",
    "1. We are given an song with `key = 3` and `energy = 0.8`. According to your KNN model, will this song be in the top half of hits?\n",
    "2. We are given another song with `key = 4.5` and `energy = 0.45`. Will this song be a bust or a hit?\n",
    "3. We are given an song with `key = 1` and `energy = 0.5`. Will this song be a bust or a hit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlpDpjwz0BP"
   },
   "outputs": [],
   "source": [
    "song = pd.DataFrame([[3, 0.8]], columns = [\"key\", \"energy\"])\n",
    "prediction = # COMPLETE THIS CODE\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Owgkh7viFwRE"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dXQz9UYFwIJ"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVzquV13hgFj"
   },
   "source": [
    "### **Reflection question**\n",
    "Answer the following question: Do you think using only the two features `energy` and `key` is enough to predict whether or not a song will be a top hit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYjkYKWK_0HT"
   },
   "source": [
    "### **Hyperparameter Tuning [OPTIONAL]**\n",
    "\n",
    "Run the given code below to find the optimal k for our model. What is this k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKhp6DIm_0HY"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "scores = {}\n",
    "for n in range(1,50,2):\n",
    "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
    "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
    "    pred = full_model.predict(X_test)\n",
    "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
    "    scores[n] = score\n",
    "\n",
    "\n",
    "plt.title(\"Accuracy on Test set across Hyperparameter values\")\n",
    "print(scores)\n",
    "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
    "\n",
    "# ADDING THE PERFORMANCE FOR K = SQRT SIZE FOR REFERENCE\n",
    "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
    "full_model = KNeighborsClassifier(n_neighbors = k)\n",
    "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
    "pred = full_model.predict(X_test)\n",
    "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
    "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
    "\n",
    "\n",
    "top_score = max(scores.values())\n",
    "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
    "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# PRINTING THE RESULTS\n",
    "print(\"Top score of optimal classifier: \" + str(top_score))\n",
    "print(\"Best Value of K to use \" + str(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBx3-jiP0zdL"
   },
   "source": [
    "<a name=\"p3\"></a>\n",
    "\n",
    "---\n",
    "## **Part 3: Australia Dataset**\n",
    "---\n",
    "#### **About the Dataset**\n",
    "Weather and humans' ability to forecast/predict it play a large role in many aspects of daily life. This dataset contains about 10 years of daily weather observations from numerous Australian weather stations.\n",
    "\n",
    "The features are as follows:\n",
    "* `Location`: the location of the weather station\n",
    "* `WindSpeed`: the wind speed averaged over 10 minutes prior to 9am (in km/hr)\n",
    "* `Humidity`: the humidity (percent) at 9am\n",
    "* `Pressure`: atmospheric pressure reduced to mean sea level at 9am (in hundreds of hPa)\n",
    "* `Temp`: temperature at 9am (in Celsius)\n",
    "* `RainToday`: whether or not the rain/precipitation in the 24 hours to 9am exceeds 1mm (0: no, 1: yes)\n",
    "* `RainTomorrow`: whether or not it rained at least 1mm the next day (0: no, 1: yes)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Your Task**\n",
    "* Build a model that can predict whether or not it will rain tomorrow.\n",
    "* Build another model with the optimal hyperparameters and compare the accuracies.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Load the code below before continuing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz7fW61r_hsO"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/the-codingschool/TRAIN/main/australia/australia_weather.csv\"\n",
    "\n",
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YyuS71I_8Hu"
   },
   "source": [
    "#### **Problem #3.1**\n",
    "\n",
    "Create a KNN model with the hyperparameter `n_neighbors = 3` in order to predict whether or not it will rain tomorrow. Use all features except `Location` and `RainTomorrow`, and then train and evaluate the model using `accuracy_score` and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGtbCrPm0zde"
   },
   "outputs": [],
   "source": [
    "features = australia_df.drop(['Location', 'RainTomorrow'], axis=1)\n",
    "label = australia_df['RainTomorrow']\n",
    "\n",
    "#split the train and test data\n",
    "# COMPLETE THIS CODE\n",
    "\n",
    "# import the KNN algorithm\n",
    "# COMPLETE THIS CODE\n",
    "\n",
    "# initialize\n",
    "# COMPLETE THIS CODE\n",
    "\n",
    "# fit\n",
    "# COMPLETE THIS CODE\n",
    "\n",
    "# predict\n",
    "# COMPLETE THIS CODE\n",
    "\n",
    "# Evaluation of accuracy\n",
    "print(\"Accuracy Score: \" + str(metrics.accuracy_score(# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IG93bpOmrEHH"
   },
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOnuhW89r04Q"
   },
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c69ICzzToxDC"
   },
   "source": [
    "<a name=\"p4\"></a>\n",
    "\n",
    "---\n",
    "## **Part 4: [OPTIONAL] Homework Practice**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I1Jg2wSymZf"
   },
   "source": [
    "<a name=\"p4.1\"></a>\n",
    "\n",
    "---\n",
    "### **Part 4.1: Zoo Animal Classification Dataset**\n",
    "---\n",
    "\n",
    "#### **About the Dataset**\n",
    "The following dataset contains information on various zoo animals, including their characteristics and classifications. Our goal is to build a model that predicts the classification of an animal based on its features.\n",
    "\n",
    "<br>\n",
    "\n",
    "The labels you will be trying to predict are as follows:\n",
    "\n",
    "* `1` -- **Mammals** (41 animals in this category): aardvark, antelope, bear, boar, buffalo, calf, cavy, cheetah, deer, dolphin, elephant, fruitbat, giraffe, girl, goat, gorilla, hamster, hare, leopard, lion, lynx, mink, mole, mongoose, opossum, oryx, platypus, polecat, pony, porpoise, puma, cat, raccoon, reindeer, seal, sealion, squirrel, vampire, vole, wallaby, wolf.\n",
    "* `2` -- **Birds** (20 animals in this category): chicken, crow, dove, duck, flamingo, gull, hawk, kiwi, lark, ostrich, parakeet, penguin, pheasant, rhea, skimmer, skua, sparrow, swan, vulture, wren.\n",
    "* `3` -- **Reptiles** (5 animals in this category): pitviper, seasnake, slowworm, tortoise, tuatara.\n",
    "* `4` -- **Fish** (13 animals in this category): bass, carp, catfish, chub, dogfish, haddock, herring, pike, piranha, seahorse, sole, stingray, tuna.\n",
    "* `5` -- **Amphibians** (4 animals in this category): frog, frog, newt, toad.\n",
    "* `6` -- **Insects** (8 animals in this category): flea, gnat, honeybee, housefly, ladybird, moth, termite, wasp.\n",
    "* `7` -- **Invertebrates** (10 animals in this category): clam, crab, crayfish, lobster, octopus, scorpion, seawasp, slug, starfish, worm.\n",
    "\n",
    "<br>\n",
    "\n",
    "The features are as follows (all features marked with an * is 1 if yes and 0 if no):\n",
    "\n",
    "\n",
    "* `animal_name`: Name of the animal\n",
    "* `hair`: Hair presence*\n",
    "* `feathers`: Feather presence*\n",
    "* `eggs`: Egg-laying ability*\n",
    "* `milk`: Milk production ability*\n",
    "* `airborne`: Ability to fly*\n",
    "* `aquatic`: Ability to live in water*\n",
    "* `predator`: Predatory behavior*\n",
    "* `toothed`: Teeth presence*\n",
    "* `backbone`: Backbone presence*\n",
    "*  `breathes`: Ability to breathe*\n",
    "* `venomous`: Venom presence*\n",
    "* `fins`: Fin presence*\n",
    "* `legs`: Number of legs (0, 2, 4, 5, 6, or 8)\n",
    "* `tail`: Tail presence*\n",
    "* `domestic`: Domestication status*\n",
    "* `catsize`: Cat-like size*\n",
    "* `class_type`: Numeric class identifier (1-7) as described above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uALsY1jv0OtU"
   },
   "source": [
    "#### **Step #1: Load the data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJf1sXiS_uHi"
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data\"'\n",
    "\n",
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DJtkoHn0bL8"
   },
   "source": [
    "#### **Step #2: Decide independent and dependent variables**\n",
    "\n",
    "Your goal is to predict `class_type` using all possible *numerical* features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7-0cUep0naJ"
   },
   "outputs": [],
   "source": [
    "features = # COMPLETE THIS CODE\n",
    "label = # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5omgCtfW1i4U"
   },
   "source": [
    "#### **Step #3: Split data into training and testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE_3S_vw1mIr"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrBakbiK1qGv"
   },
   "source": [
    "#### **Step #4: Import your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-KRBRBN1s3W"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEBL8QJ811ZN"
   },
   "source": [
    "#### **Step #5: Initialize your model and set hyperparameters**\n",
    "\n",
    "Initialize the KNN model, and set hyperparameter `n_neighbors = 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPq8Sokb167W"
   },
   "outputs": [],
   "source": [
    "model = # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTpPtWDz1-YZ"
   },
   "source": [
    "#### **Step #6: Fit your model, test on the testing data**\n",
    "\n",
    "**NOTE**: Visualization would be quite tricky here since there are 16 features instead of just 2. So, do not worry about doing this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7s6t9fF2BnG"
   },
   "outputs": [],
   "source": [
    "model.# COMPLETE THIS CODE\n",
    "pred = # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZbsJfYtGQz2"
   },
   "source": [
    "#### **Step #7: Evaluate your model**\n",
    "\n",
    "Print the accuracy and confusion matrix for your model's performance on the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE**: In this case, the labels are already the names of the classes as opposed to less meaningful numbers, so you do not need to supply a `display_labels` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCYWHxhiGQz3"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score: \", # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JppmTSVoGQz3"
   },
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxfdmNbVmJuq"
   },
   "source": [
    "<a name=\"p4.2\"></a>\n",
    "\n",
    "---\n",
    "### **Part 4.2: Classifying Stars**\n",
    "---\n",
    "In this Part, we will use a dataset that contains data collected by astronomers about different classes of stars that have been observed. With KNN, you will use the size and temperature of stars to determine which class they may be from the following:\n",
    "\n",
    "* `0`: Red Dwarf\n",
    "* `1`: Brown Dwarf\n",
    "* `2`: White Dwarf\n",
    "* `3`: Main Sequence\n",
    "* `4`: SuperGiants\n",
    "* `5`: HyperGiants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCFtCV4tmJu0"
   },
   "source": [
    "#### **Step \\#1: Load the data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLfL64KK_0Kh"
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTCZgoegOHa49SFXYU-ZZTdCkgTp0sneU1BsEOa7vusjTXPPLcn0i3kXhX1nyqkApJHCKTkw0mWuWr4/pub?gid=753880827&single=true&output=csv'\n",
    "\n",
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0fsjaktmJu0"
   },
   "source": [
    "#### **Step \\#2: Decide independent and dependent variables**\n",
    "\n",
    "Use the dataframe `stars_df` and subset your data into `inputs` and `output`.\n",
    "\n",
    "<br>\n",
    "\n",
    "The `inputs` will be `size` and `temperature`.\n",
    "\n",
    "The `output` will be `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIGykhmeQzf7"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6ij7uTDmJu1"
   },
   "source": [
    "#### **Step \\#3: Split data into train and test data**\n",
    "\n",
    "Let's split your data into training and testing data. Since this is a small dataset, let's just reserve 10% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "piz2rHXbQvcS"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAl_9jbkmJu1"
   },
   "source": [
    "#### **Step \\#4: Import your model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66liNofsQuu6"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSFm8SYpmJu1"
   },
   "source": [
    "#### **Step \\#5: Initialize your model and set hyperparameters**\n",
    "\n",
    "Build your model with $K=7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDufCenCQt8m"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtBikiJdmJu1"
   },
   "source": [
    "#### **Step \\#6: Fit your model and make a prediction**\n",
    "\n",
    "Train your model with the `x_train` and `y_train` training data and make predictions on `x_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gZS2U1aQrh9"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aa9e44fqnnf7"
   },
   "source": [
    "#### **Create a visualization**\n",
    "\n",
    "**Run the code below to visualize the decision boundary of this KNN model.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EtBQwK1nnf7"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(0, 2000, 10),\n",
    "                     np.arange(1900, 40000, 100))\n",
    "z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z = z.reshape(xx.shape)\n",
    "\n",
    "ax.pcolormesh(xx, yy, z, alpha=0.1)\n",
    "\n",
    "labels = ['Red Dwarf', 'Brown Dwarf', 'White Dwarf', 'Main Sequence', 'SuperGiants', 'HyperGiants']\n",
    "for label, data in stars_df.groupby('class'):\n",
    "  ax.scatter(data[\"size\"], data[\"temperature\"], label=labels[label])\n",
    "\n",
    "ax.set_title(\"Decision Boundary of the KNN Classifier\")\n",
    "ax.set_xlabel(\"Star Size\")\n",
    "ax.set_ylabel(\"Star Temperature\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWLwxZhIQDTM"
   },
   "source": [
    "#### **Step #7: Evaluate your model**\n",
    "\n",
    "Print the accuracy and confusion matrix for your model's performance on the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE**: It's not necessary to supply a `display_labels` argument, but if you are curious see if you can use the information provided in this Part to supply them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMfXJWG0QDTN"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score: \", # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcHyqz5cQDTN"
   },
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGoZURsgmJu1"
   },
   "source": [
    "#### **Step \\#8: Make predictions**\n",
    "\n",
    "\n",
    "Astronomers have heard of your amazing ML model for predicting star types and want you to help them categorize new stars they have observed! For each problem below, use your KNN model to classify the stars based on the data given to you.\n",
    "\n",
    "\n",
    "1. `size`: 708.9, `temperature`: 12100 (`[708.9, 12100]`)\n",
    "\n",
    "2. `size`: 0.0998, `temperature`:  3484 (`[0.0998, 3484]`)\n",
    "\n",
    "3. `size`: 6.39, `temperature`:  34190 (`[6.39, 34190]`)\n",
    "\n",
    "4. `size`: 0.16, `temperature`: 2799 (`[0.16, 2799]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7b0UAlTQmvz"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QH6aPxM3Qpkp"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LShnE8d-QpbB"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVW-ZPYoQpM-"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHaoB5X9GIzo"
   },
   "source": [
    "<a name=\"p4.3\"></a>\n",
    "\n",
    "---\n",
    "### **Part 4.3: RGB Color Classification Dataset**\n",
    "---\n",
    "\n",
    "Visible colors of light (for humans) and digital colors can be represented in the form of RGB values. The **RGB color model** operates as an additive system where <font color=\"red\">red</font>, <font color=\"green\">green</font>, and <font color=\"#2964f0\">blue</font> (**<font color=\"red\">R</font><font color=\"green\">G</font><font color=\"#2964f0\">B</font>**) primary light colors combine in diverse ways to replicate a wide spectrum of colors.\n",
    "\n",
    "Each of these primary colors is represented by an integer value between 0 and 255 (just under 256 or 2<sup>8</sup> on the binary number scale). A lower value means a lower intensity or darker color. Likewise, an RGB of (0, 0, 0) is black, while (255, 255, 255) is white. The closer the red, green, and blue values are to being equal, the more likely a color is to appear gray. For example, RGB(113, 113, 113) and RGB(207, 207, 207) are different shades of gray.\n",
    "\n",
    "Without checking, what color would RGB(172, 145, 236) be? <br />That's a tough question to answer!\n",
    "\n",
    "Naturally, we as humans often use names to describe colors as we see them. You may have grown up using crayons with names like *scarlet*, *dark purple*, or *yellow-orange*. But where is the line between *orange* and *yellow* drawn? Classifying colors under an umbrella label can be difficult and is often individually or even culturally subjective! This task becomes even more challenging for those with a form of color blindness.\n",
    "\n",
    "Beyond the commonly known groupings of primary, secondary, and tertiary colors, [research](https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC1618485&blobtype=pdf) has found an optimitzed set of 11 distinct color categories for classification: <br />\n",
    "> *Red, Orange, Yellow, Green, Blue, Purple, Pink, Brown, Black, Gray, White*\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "---\n",
    "\n",
    "#### **About the Dataset**\n",
    "\n",
    "This dataset contains 5053 RGB color samples that have been labelled into one of 11 different categories.\n",
    "\n",
    "This **[Google Color Picker](https://www.google.com/search?rls=en&q=color+picker)** may be a handy tool to use throughout this section!\n",
    "\n",
    "The features are as follows:\n",
    "\n",
    "- `red` - RGB red value ( integer 0-255 )\n",
    "\n",
    "- `green` - RGB green value ( integer 0-255 )\n",
    "\n",
    "- `blue` - RGB blue value ( integer 0-255 )\n",
    "\n",
    "- `label` - color category, there are 11 total:\n",
    "\n",
    "    - *Red, Orange, Yellow, Green, Blue, Purple, Pink, Brown, Black, Gray, White*\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **Your Task**\n",
    "Using the RGB Color Classification dataset, you will do the following:\n",
    "* Create a KNN model that can predict the categorization of a color based on its red, green, and blue values.\n",
    "* Plot and compare the results and make note of your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hn0cpJ4KG4I4"
   },
   "source": [
    "#### **Step #1: Load the data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAaPQol5_6tU"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/the-codingschool/TRAIN/main/color_classification/color_data.csv\"\n",
    "\n",
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-SRaUwf0_NJ"
   },
   "source": [
    "#### **Step #2: Create visualizations to get familiar with the data**\n",
    "\n",
    "First, create either a bar graph or histogram to visualize the distribution of color categories in the dataset.\n",
    "\n",
    "Challenge: If you can, try to color the bars the same as the corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3ODy_9mOrev"
   },
   "outputs": [],
   "source": [
    "colors = list(rgb_df['label'].unique())\n",
    "total_num_of_each_color = [rgb_df['label'].value_counts()[c] for c in colors]\n",
    "\n",
    "plt.axes().set_facecolor('lightgray')\n",
    "plt.bar(# COMPLETE THIS CODE\n",
    "\n",
    "# COMPLETE THIS CODE - axis labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj4g0aV34zdS"
   },
   "source": [
    "\n",
    "Since there are three separate values that make up an RGB color, let's use a **3D scatter plot** to visualize the spread of the data. We can color the points with either their color label or with the actual RGB hue if we condense the three values into a single representation.\n",
    "\n",
    "- **`make_hex()`** - Takes a dataframe row (with the features ['red', 'green', 'blue']) as a parameter and returns the hexadecimal equivalent as a string. When used with the `df.apply()` method, it can create an entire new column of hex codes ready to be added to the dataframe as a new column.\n",
    "\n",
    "  ```\n",
    "  df['hex'] = df.apply(make_hex, axis=1)\n",
    "  ```\n",
    "\n",
    "  To learn more about the process of converting RGB to HEX, see the infographic below.\n",
    "\n",
    "  <img src=\"https://raw.githubusercontent.com/the-codingschool/TRAIN/main/color_classification/RGB to HEX.jpg\" width=600/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_btmXWPI75b"
   },
   "outputs": [],
   "source": [
    "def make_hex(row):\n",
    "  return '#%02X%02X%02X' % (row['red'], row['green'], row['blue'])\n",
    "\n",
    "fig = plt.figure(figsize=(14,8), layout='tight')\n",
    "\n",
    "# RGB-HEX Colors\n",
    "ax = fig.add_subplot(121,projection='3d')\n",
    "ax.scatter(rgb_df['red'], rgb_df['green'], rgb_df['blue'], c=rgb_df.apply(make_hex, axis=1), s=8, alpha=1.0)\n",
    "ax.set_title('Actual Colors', fontweight='bold')\n",
    "ax.set_xlabel('Red  ', fontweight='bold', color='red')\n",
    "ax.set_ylabel('Green', fontweight='bold', color='green')\n",
    "ax.set_zlabel('Blue ', fontweight='bold', color='blue')\n",
    "ax.set_box_aspect(None, zoom=0.85)\n",
    "\n",
    "# Label Colors\n",
    "ax = fig.add_subplot(122,projection='3d')\n",
    "ax.scatter(rgb_df['red'], rgb_df['green'], rgb_df['blue'], c=rgb_df['label'], s=8)\n",
    "# COMPLETE THIS CODE - title, axis labels, aspect\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0kwslkFJLvO"
   },
   "source": [
    "#### **Step #3: Decide independent and dependent variables**\n",
    "\n",
    "For this problem, we are interested in how the `red`, `green`, and `blue` values affect what name is given to a color. Since the `label` of a color is a string, we also need to *encode* the color labels by assigning a number to each one.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35Dqmq3wIyAf"
   },
   "outputs": [],
   "source": [
    "encoded_labels = [colors.index(c) for c in rgb_df['label']]\n",
    "features = # COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwOH_VssvQQI"
   },
   "source": [
    "#### **Step #4: Split data into training and testing data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8r9CoIZiItno"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8B6OJ4SvcER"
   },
   "source": [
    "#### **Step #5: Hyperparameter Tuning**\n",
    "\n",
    "Complete and run the given code below to find the optimal k for our model. What is this k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1C04D-WzAwLY"
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for n in range(1,60,2):\n",
    "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
    "    full_model.fit(X_train, y_train)\n",
    "    pred = full_model.predict(X_test)\n",
    "    scores[n] = sum(pred == y_test)/len(pred) * 100\n",
    "\n",
    "\n",
    "plt.title(\"Accuracy on Test set across Hyperparameter values\")\n",
    "plt.plot(scores.keys(), scores.values(), label = 'Scores for all K')\n",
    "\n",
    "top_score = max(scores.values())\n",
    "best_k = {v:k for k,v in scores.items()}[top_score]\n",
    "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
    "\n",
    "plt.xlabel('K-Neighbors')\n",
    "plt.ylabel('Prediction Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top score of optimal classifier: \" + str(top_score))\n",
    "print(\"Best Value of K: \" + str(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHWQG5xJv1rb"
   },
   "source": [
    "#### **Step #6: Initialize & Evaluate the model using the optimal k value**\n",
    "\n",
    "\n",
    "After fitting your model and making a prediction, print the accuracy and confusion matrix for your model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOF8Axl9HP8K"
   },
   "outputs": [],
   "source": [
    "# COMPLETE THIS CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oczoaQlu8thP"
   },
   "source": [
    "#### **Step #7: Visualize your results**\n",
    "\n",
    "Analyzing colors can be an intensely visual process, and evaluating model predictions may heavily rely on visual confirmation. Because of this, it is incredibly helpful to have stylized outputs that reflect the actual color of the sample and the color of the label it has been assigned. The way we perceive colors is often subjective, and the boundary that separates one color from its neighbor on the spectrum isn't rigidly defined.\n",
    "\n",
    "Your task is to compile the actual labels, predicted labels, and hex codes into a single dataframe as columns. Then we can use special output styling techniques to manually compare the actual and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YICPIXGYHnSL"
   },
   "outputs": [],
   "source": [
    "actual_labels = [colors[l] for l in y_test]   # return the encoded labels to the color names\n",
    "predicted_labels = [# COMPLETE THIS CODE\n",
    "\n",
    "results_df = X_test.copy()\n",
    "results_df['actual'] = # COMPLETE THIS CODE\n",
    "results_df['predicted'] = # COMPLETE THIS CODE\n",
    "results_df['hex'] = # COMPLETE THIS CODE\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzr0sM2L_Z07"
   },
   "source": [
    "##### **Styled Table Output**\n",
    "\n",
    "- `output_styling()` - Takes a feature column as a parameter and returns a list of styling instructions for each column value as strings. These styling instructions are CSS ([cascading style sheets](https://www.w3schools.com/css/css_intro.asp)) ***attribute:value*** pairs. The primary attributes to consider are:\n",
    "    - **Background Color** `background-color` - Accepts hex codes (ex: #012D9C) and some standard [color names](https://developer.mozilla.org/en-US/docs/Web/CSS/named-color) (ex: 'red'). At a glance, the background should show us exactly what the sample color looks like *(hex code)*.\n",
    "    - **Text Color** `color` - Accepts hex codes (ex: #012D9C) and some standard [color names](https://developer.mozilla.org/en-US/docs/Web/CSS/named-color) (ex: 'red').\n",
    "    - **Text Alignment** `text-align` - Will align text to the left, right, or center of the cell.\n",
    "  \n",
    "  When the name of this function is used as a parameter in this method call `df.style.apply()` it is called on each feature column in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSHlLpadwfQp"
   },
   "outputs": [],
   "source": [
    "def output_styling(column):\n",
    "  if column.name == 'hex':\n",
    "    return ['text-align: center; background-color: ' + val for val in column]\n",
    "  if column.name not in ['red','green','blue']:\n",
    "    return ['text-align: center; font-weight: bold; color: ' + val for val in column]\n",
    "  return ['' for val in column]\n",
    "\n",
    "results_df.style.apply(output_styling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QqMmCxKAyh_"
   },
   "source": [
    "---\n",
    "\n",
    " **[OPTIONAL]**\n",
    "\n",
    "Make additional 3D scatter plots of the RGB color data used to test the model. Consider comparing the actual/predicted labels and the actual RGB color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5YhFwi_IAx0"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17,8), layout='tight')\n",
    "\n",
    "# Actual Label\n",
    "ax = fig.add_subplot(131,projection='3d')\n",
    "ax.scatter(# COMPLETE THIS CODE\n",
    "ax.set_title('Actual Color Labels', fontweight='bold')\n",
    "ax.set_xlabel('Red  ', fontweight='bold', color='red')\n",
    "ax.set_ylabel(# COMPLETE THIS CODE\n",
    "ax.set_zlabel(# COMPLETE THIS CODE\n",
    "ax.set_box_aspect(None, zoom=0.85)\n",
    "\n",
    "# Predicted Label\n",
    "ax = fig.add_subplot(132,projection='3d')\n",
    "# COMPLETE THIS CODE\n",
    "\n",
    "\n",
    "# RGB-HEX Colors\n",
    "ax = fig.add_subplot(133,projection='3d')\n",
    "# COMPLETE THIS CODE\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRcj78PpQ2Xz"
   },
   "source": [
    "---\n",
    "\n",
    "# End of Notebook\n",
    "\n",
    "© 2024 The Coding School, All rights reserved"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wVQU5DEggnZK",
    "UxfdmNbVmJuq",
    "LHaoB5X9GIzo"
   ],
   "provenance": [
    {
     "file_id": "1iG6sfC7X_4Yhq6kvpSXOdGOp2pFId7B6",
     "timestamp": 1731350992009
    },
    {
     "file_id": "1E7XzEfGPZnFcMHZBy0An05w7HJE3oKiZ",
     "timestamp": 1687280614101
    },
    {
     "file_id": "1w0oSZLFTuod5eGnI-NrRr4AyZnTci5CZ",
     "timestamp": 1684943334274
    },
    {
     "file_id": "1Xfzh5FDgqUr6GJtTecxh-SoZ-qiOK1kJ",
     "timestamp": 1661563000718
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
