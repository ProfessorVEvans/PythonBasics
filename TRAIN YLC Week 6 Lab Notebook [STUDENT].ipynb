{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Lab 6: Linear Regression Part I**\n","---\n","\n","### **Description**\n","In this lab, you will learn how to build linear regression models using sklearn.\n","\n","</br>\n","\n","### **Lab Structure**\n","**Part 1**: [Boston Housing Dataset](#p1)\n","\n","**Part 2**: [Diabetes Dataset](#p2)\n","\n","</br>\n","\n","### **Learning Objectives**\n"," By the end of this lab, you will:\n","1. Recognize what sklearn is and why we're using it.\n","2. Recognize how to implement Linear Regression models with sklearn.\n","\n","\n","</br>\n","\n","### **Cheat Sheets**\n","* [Linear Regression with sklearn](https://docs.google.com/document/d/18NpkZHfcdrFd6IKBlZduMk_AWZiHgB3YsN7mLofTq-M/edit?usp=drive_link)\n","\n","<br>\n","\n","**Run the cell below to import the necessary libraries and functions.**"],"metadata":{"id":"YIlQ_30ypxfZ"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn import datasets, model_selection\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error"],"metadata":{"id":"2OiK0-eyq9e6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a name=\"p1\"></a>\n","\n","---\n","## **Part 1: Boston Housing Dataset**\n","---\n","\n","#### **About the Dataset**\n","For a long time, House Price Index (HPI), which measures price changes of residential housing, has been used to predict the price of a specific house. However, HPI is focused on measuring the average price changes in repeat sales or refinancing on the same properties over time, meaning that many features, such as the house's district, age, or number or floors, are not considered. As a result of HPI's deficiencies, in recent years, Machine Learning techniques have been used to predict individual housing prices.\n","\n","\n","The Boston Housing Dataset is a collection of data that contains information on various features of houses in the Boston area, such as the number of rooms, the age of the house, and the distance to employment centers. The dataset contains 13 numerical features and a numerical target. It is often used for regression analysis and is a popular benchmark dataset for machine learning algorithms.\n","\n","The features are as follows:\n","\n","* `crim`: Per capita crime rate by town\n","* `zn`: Proportion of residential land zoned for lots over 25,000 sq. ft\n","* `indus`: Proportion of non-retail business acres per town\n","* `chas`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n","* `nox`: Nitric oxide concentration (parts per 10 million)\n","* `RM`: Average number of rooms per dwelling\n","* `age`: Proportion of owner-occupied units built prior to 1940\n","* `dis`: Weighted distances to five Boston employment centers\n","* `rad`: Index of accessibility to radial highways\n","* `tax`: Full-value property tax rate per 10,000 dollars\n","* `ptratio`: Pupil-teacher ratio by town\n","* `b`: 1000(Bk — 0.63)², where Bk is the proportion [of people of African American descent] by town\n","* `LSTAT`: Percentage of lower status of the population\n","* **`TARGET`** (target that needs to be added): Median value of owner-occupied homes in $1000s. *You need to add this column after loading the Boston data from sklearn datasets*.\n","\n","<br>\n","\n","**NOTE**: The Boston housing prices dataset has a noted ethical problem: the authors of this dataset engineered a non-invertible variable “B” assuming that racial self-segregation had a positive impact on house prices. This variable is likely due to the practice of ['Redlining'](https://www.wgbh.org/news/local-news/2019/11/12/how-a-long-ago-map-created-racial-boundaries-that-still-define-boston) from the 1930s to 1970s in Boston, which has had long lasting affects in Boston still present today. The goal of the research that led to the creation of this dataset was to study the impact of air quality, but it did not give adequate demonstration of the validity of this assumption. Please know this data set is used for *practice only* and can serve as a good example of why ethical standards are so important for ML models and implementation. [Read more](https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8) on problems existing within this data set and why it is not used for anything other than practicing ML.\n","\n","<br>\n","\n","#### **Your Task**\n","Using the Boston Housing dataset, we will do the following:\n","* Build a model that will predict the median value of owner-occupied homes for Boston in the 1970s;\n","* Use the model to predict the median value of houses with various room numbers and LSTAT scores.\n"],"metadata":{"id":"3f6t0yYBhCsm"}},{"cell_type":"markdown","source":["#### **Step #1: Load the data**\n"],"metadata":{"id":"Jrbb0BuorRTK"}},{"cell_type":"code","source":["url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n","df = pd.read_csv(url)\n","df = df.rename(columns={'medv': 'TARGET', 'rm': 'RM', 'lstat':'LSTAT'})\n","df.head()"],"metadata":{"id":"3X4RLiyYizVx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #2: Decide independent and dependent variables**\n","\n","\n","We are going to use \"Rooms per dwelling\" (`RM`) and \"Percentage of lower status of the population\" (`LSTAT`) as our independent variables for predicting `TARGET`. Our target is the median value of owner-occupied homes. **With these values, we are building a housing value predictor for Boston in the 1970s.** This step has already been done for you."],"metadata":{"id":"HYlGaXV3rZfY"}},{"cell_type":"code","source":["df[[\"RM\",\"LSTAT\", \"TARGET\"]]"],"metadata":{"id":"uU0u-IaDizsR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Before we continue, we will create two graphs. One with `LSTAT` and the target, and another with `RM` and the target to explore the relationship between the variables further.**"],"metadata":{"id":"q_eLEi5MiiPb"}},{"cell_type":"code","source":["plt.figure(figsize=(20, 5))\n","\n","features = df[['LSTAT', 'RM']]\n","target = df['TARGET']\n","\n","plt.subplot(1, 2, 1)\n","x = df[\"LSTAT\"]\n","y = target\n","plt.scatter(x, y, marker='o')\n","plt.title(\"LSTAT\")\n","plt.xlabel(\"LSTAT\")\n","plt.ylabel('target')\n","\n","plt.subplot(1, 2, 2)\n","x = df[\"RM\"]\n","y = target\n","plt.scatter(x, y, marker='o')\n","plt.title(\"RM\")\n","plt.xlabel(\"RM\")\n","plt.ylabel('target')"],"metadata":{"id":"BxDxSgcoi0Kg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #3: Split data into training and testing data**\n","\n","Specifically ensure the test set is 20% of the overall data. This will be the assumption moving forward."],"metadata":{"id":"HAWp_v2XsGp0"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = model_selection.train_test_split(# COMPLETE THIS LINE"],"metadata":{"id":"KvDFJJYEkp8D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #4: Import your algorithm**\n"],"metadata":{"id":"fF3UEeSjsQIm"}},{"cell_type":"code","source":["# import that LinearRegression algorithm\n","from sklearn.linear_model import LinearRegression"],"metadata":{"id":"aZPn1IAIixnU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #5: Initialize your model and set hyperparameters**\n","\n","\n","Linear regression takes no hyperparameters, so we only need to initialize the model."],"metadata":{"id":"a--9MAucsbP_"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"B_zQuzK3kuKQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #6: Fit your model, test on the testing data, and create a visualization if applicable**"],"metadata":{"id":"wzsWL1-jssDD"}},{"cell_type":"code","source":[],"metadata":{"id":"CP2QQOaBkwlc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Create a visualization**\n","\n","Use `y_test` and your `prediction` (x and y on graph) from the model to create a scatter plot. Then use the following line to visualize where a correct prediction would be:\n","```\n","plt.plot([0, 50], [0, 50], '--k', label=\"Correct prediction\")\n","```\n","\n","This step has already been done for you."],"metadata":{"id":"u4EGuo2BvAWd"}},{"cell_type":"code","source":["plt.figure(figsize=(8, 8))\n","plt.scatter(y_test, pred)\n","plt.plot([0, 50], [0, 50], '--k', label=\"Correct prediction\")\n","plt.axis('tight')\n","plt.xlabel('True price ($1000s)')\n","plt.ylabel('Predicted price ($1000s)')\n","plt.title(\"Real vs predicted house prices in Boston\")\n","plt.legend()\n","plt.tight_layout()"],"metadata":{"id":"AkCjm5-JmaLr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #7: Evaluate your model**\n","\n","\n","Use mean squared error and the R2 score as the evaluation metrics."],"metadata":{"id":"MRav6EEBtEdO"}},{"cell_type":"code","source":[],"metadata":{"id":"3r_jos6skz7b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #8: Use the model**\n","\n","Using the model we created, predict the price of three houses in Boston:\n","\n","* House 1:  7 rooms and LSTAT is 5.0%\n","\n","* House 2:  6 rooms and LSTAT is 4.0%\n","\n","* House 3: 8 rooms and LSTAT is 15.0%\n","\n","**NOTE**: you must create a dataframe containing with the information of the new houses:\n","\n","```python\n","new_houses = pd.DataFrame(enter_new_house_data_here, columns = [\"RM\", \"LSTAT\"])\n","```\n","\n","This `new_houses` variable can then be placed directly into the `model.predict()` function."],"metadata":{"id":"FP-SqsUctlcO"}},{"cell_type":"code","source":[],"metadata":{"id":"ZueyRpTMk2JM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Reflection questions**\n","Answer the following questions:\n","\n","1. How well did our model perform?\n","2. Would you rather buy House 1, House 2, or House 3? Why?"],"metadata":{"id":"omgegSJa9dR9"}},{"cell_type":"markdown","source":["<a name=\"p2\"></a>\n","\n","---\n","## **Part 2: Diabetes Dataset**\n","---\n","#### **About the Dataset**\n","Diabetes is the 8th leading cause of death in the United States. More than 37 milion people in the U.S. have diabetes, and one in 5 of these individuals do not know it. This dataset contains data from diabetic patients with features such as their BMI, age, blood pressure, and glucose levels, which are useful in predicting the diabetes disease progression in patients. We will be looking at these variables to help predict disease progression in diabetic patients.\n","\n","The features are as follows:\n","* `AGE`: age (in years)\n","* `SEX`\n","* `BMI`: body mass index\n","* `BP`: average blood pressure\n","* `S1`: tc, total serum cholesterol\n","* `S2`: ldl, low-density lipoproteins\n","* `S3`: hdl, high-density lipoproteins\n","* `S4`: tch, total cholesterol / HDL\n","* `S5`: ltg, possibly log of serum triglycerides level\n","* `S6`: glu, blood sugar level\n","* `Y`: quantitative measure of disease progression one year after baseline\n","\n","**NOTE**: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of the number of samples (i.e. the sum of squares of each column totals 1).\n","\n","#### **Your Task**\n","Using the Diabetes dataset, you will do the following:\n","* Build a model that will predict disease progression in diabetic patients;\n","* Predict the disease progression of a patient with various ages, BMIs, and blood pressures."],"metadata":{"id":"A0CMPq525kSi"}},{"cell_type":"markdown","source":["#### **Step #1: Load the data**"],"metadata":{"id":"YQPB7XZ9v-sn"}},{"cell_type":"code","source":["file = \"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\"\n","df = pd.read_table(file, header=0, delim_whitespace=True)\n","df.head()"],"metadata":{"id":"C1rwfTb_rXia"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #2: Decide independent and dependent variables**\n","\n","Here we would like to use the `AGE` `BMI` and `BP` columns as our independent variables and `Y` as our dependent variable.\n","\n","We are building a predictor of disease progression.\n"],"metadata":{"id":"E5z0mLEQF565"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"Le7RzFSXS7FW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #3: Split data into training and testing data**\n","\n","Use `AGE`, `BMI`, and `BP` for our independent variables."],"metadata":{"id":"lMDn8ONk600c"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"IOuMRPdQlAVz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #4: Import your model**"],"metadata":{"id":"5ADG4KRM69dJ"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"VZMm4IAClBLO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #5: Initialize your model and set hyperparameters**\n","\n","\n","Linear regression takes no hyperparameters, so just initialize the model."],"metadata":{"id":"PFUiA67CHAMc"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"faXqWmQElEFD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #6: Fit your model, test on the testing data, and create a visualization if applicable**"],"metadata":{"id":"xMnlj4W0HF9U"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"h5iPDJmJlFAQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Create a visualization**\n","\n","Use `y_test` and your `prediction` from the model to create a scatter plot. Then use the following line to visualize where a correct prediction would be. The code has already been given to you.\n","```\n","plt.plot([0, 300], [0, 300], '--k', label=\"Correct prediction\")\n","```"],"metadata":{"id":"6DmQtTt9HNJE"}},{"cell_type":"code","source":["plt.figure(figsize=(8, 8))\n","\n","\n","\n","plt.scatter(# COMPLETE THIS CODE\n","plt.plot(# COMPLETE THIS CODE, '--k', label=\"Correct prediction\")\n","\n","\n","plt.axis('tight')\n","\n","plt.xlabel(# COMPLETE THIS CODE\n","plt.ylabel(# COMPLETE THIS CODE\n","plt.title(# COMPLETE THIS CODE\n","\n","\n","plt.legend()\n","plt.tight_layout()"],"metadata":{"id":"-kRYw_V5y9qP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #7: Evaluate your model**\n","\n","Use mean squared error and the R2 score as the evaluation metrics.\n"],"metadata":{"id":"9hqWuSqc7Tpp"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"9Q0ABlESlNDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Step #8: Use the model**\n","\n","Using the model we created, predict the disease progression of two new patients:\n","\n","* Patient 1:  age 45, bmi of 26.3, and average blood pressure of 98\n","\n","* Patient 2:  age 39, bmi of 22.7, and average blood pressure of 114\n","\n","**NOTE**: you must create a dataframe containing with the information of the new patients:\n","\n","```python\n","new_patient_data = pd.DataFrame(new_patient_data_here, columns =[\"AGE\", \"BMI\", \"BP\"])\n","```"],"metadata":{"id":"kKm0SpTVQMkn"}},{"cell_type":"code","source":["# COMPLETE THIS CODE"],"metadata":{"id":"I6lImblY6OM-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Reflection questions**\n","Answer the following questions based on the scatter plot:\n","\n","1. Does your model tend to overpredict or underpredict for a true progression value less than 150?\n","2. Does your model tend to overpredict or underpredict for a true progression value above 150?"],"metadata":{"id":"gHZtBij9Lw6_"}},{"cell_type":"markdown","source":["---\n","#End of Notebook\n","\n","© 2023 The Coding School, All rights reserved"],"metadata":{"id":"yt29TPJXhU9Q"}}]}